# AirSight
AirSight is a real-time multimodal drone detection system that uses both camera and microphone data. It combines CNN-based visual features with MFCC audio features in a lightweight neural network, making it suitable for deployment on edge devices like Jetson Nano or Raspberry Pi.

---

## ğŸ§  Overview

AirSight leverages two sensory modalitiesâ€”image and soundâ€”for robust drone classification. It is built on PyTorch and OpenCV and supports live webcam feed and microphone input for continuous detection.

### Key Features
- ğŸ–¼ï¸ **Visual Detection**: Captures and processes 64x64 RGB frames from a webcam.
- ğŸ”Š **Audio Detection**: Captures 1-second microphone samples and extracts MFCCs.
- ğŸ§© **Multimodal Fusion**: Combines visual and audio features in a neural network.
- âš¡ **Real-Time Inference**: Fast enough for real-time classification.
- ğŸ“¦ **Lightweight Model**: Designed to run on laptops and edge devices.

---

## ğŸ“ Project Structure

```
AirSight/
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ fusion_model_tf.pth        # Trained model weights
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ rt_inference.py            # Real-time inference script
â”‚
â”œâ”€â”€ data/                          # Paired image/audio dataset (not included)
â”‚
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/airsight.git
   cd airsight
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Ensure you have a microphone and webcam connected.

---

## ğŸš€ Running Real-Time Inference

```bash
python scripts/rt_inference.py
```

Press `q` to quit the live window.

---

## ğŸ“Š Model Architecture

```text
Image Input  â†’ CNN (Conv â†’ ReLU â†’ Pool â†’ Flatten)
Audio Input  â†’ MFCC â†’ Linear â†’ ReLU
              â†“
          Concatenate â†’ Linear â†’ Softmax
```

---

## ğŸ§ª Training (Optional)

Training scripts are not included but the dataset was created by pairing:

- **Images** from: [Drone Type Classification (Kaggle)](https://www.kaggle.com/datasets/balajikartheek/drone-type-classification)
- **Audio** from: [Drone Audio Dataset (GitHub)](https://github.com/saraalemadi/DroneAudioDataset)

Each image-audio pair was labeled as "Drone" or "No Drone".

---

## ğŸ’¡ Applications

- Perimeter surveillance
- Wildlife protection
- Anti-drone defense
- Smart city monitoring

---

## âš ï¸ Disclaimer

This project is intended for research and educational purposes. Accuracy and real-world robustness may vary with conditions.

---

## ğŸ“„ License

[MIT License](LICENSE)

---

## ğŸ™‹â€â™‚ï¸ Maintainer

Developed by [Your Name], CFI, IIT Madras  
Contributions are welcome!
